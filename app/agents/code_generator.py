"""
Code Generator Agent - Generates actual code patches for top issues
"""
import json
from typing import List, Optional
from app.schemas.outputs import FetchedItem, PriorityEntry, FixPlan
from app.llm import LLMClient


CODE_GENERATOR_PROMPT = """You are an expert software engineer who helps developers understand how to fix issues.

Your task is to generate PSEUDOCODE with explanatory comments that guides developers on how to fix the issue.

Given:
- Issue description and context
- A detailed fix plan
- File paths that likely need changes

Generate:
1. PSEUDOCODE with inline comments explaining the fix approach (this is what the developer will see first)
2. Optionally, a full AI-generated code implementation (this will be hidden by default)
3. Clear explanation of what the fix does
4. Confidence score (0.0-1.0) based on how certain you are about the fix

Guidelines for PSEUDOCODE:
- Use /// comments to explain each step of the fix
- Show the logical structure without worrying about exact syntax
- Focus on clarity and educational value
- Help the developer understand WHY each change is needed
- Example format:
  /// Add connection timeout handling
  async function sendRequest(request) {
    /// Create abort controller for timeout
    const controller = new AbortController();
    /// Set timeout to 5 seconds
    setTimeout(() => controller.abort(), 5000);
    /// Attempt request with timeout signal
    try {
      return await fetch(request.url, { signal: controller.signal });
    } catch (error) {
      /// Handle timeout errors appropriately
      if (error.name === 'AbortError') {
        throw new Error('Connection timed out');
      }
      throw error;
    }
  }

Output ONLY valid JSON in this exact format:
{
  "patch": {
    "issue_number": 123,
    "file_path": "src/auth/handler.ts",
    "pseudocode": "/// Add null check to prevent undefined token errors\nfunction authenticateUser(token) {\n  /// Validate token exists before processing\n  if (!token) {\n    throw new Error('Token is required');\n  }\n  /// Continue with authentication logic\n  // ... rest of implementation\n}",
    "explanation": "Added null check to prevent undefined token errors. This addresses the authentication bug by validating input before processing.",
    "confidence": 0.75,
    "approach": "defensive-validation",
    "notes": "Integrate this with your existing error handling framework.",
    "full_code": "function authenticateUser(token: string): AuthResult {\n  if (!token || token.trim() === '') {\n    throw new AuthenticationError('Token is required');\n  }\n  return processToken(token);\n}"
  }
}

If you cannot generate a reasonable patch (too little context), set confidence to 0.0 and explain why."""


async def generate_code_patch(
    top_issue: PriorityEntry,
    fix_plan: FixPlan,
    item: FetchedItem,
    llm_client: LLMClient
) -> Optional[dict]:
    """
    Generate code patch for the top priority issue
    
    Args:
        top_issue: The highest priority issue
        fix_plan: The fix plan for this issue
        item: Full issue details
        llm_client: LLM client for generation
        
    Returns:
        Dictionary with patch data or None if generation fails
    """
    # Prepare context for code generation
    context = {
        "issue": {
            "number": top_issue.number,
            "title": top_issue.title,
            "body": item.body[:1000] if item.body else "",  # First 1000 chars
            "severity": top_issue.severity,
            "impact": top_issue.impact,
        },
        "fix_plan": {
            "steps": fix_plan.plan,
            "files": fix_plan.files_likely_touched,
            "edge_cases": fix_plan.edge_cases,
            "acceptance_criteria": fix_plan.acceptance_criteria,
        }
    }
    
    messages = [
        {"role": "system", "content": CODE_GENERATOR_PROMPT},
        {"role": "user", "content": f"Generate a code patch for this issue:\n\n{json.dumps(context, indent=2)}"}
    ]
    
    try:
        response = await llm_client.completion_json(messages, temperature=0.4, max_tokens=3096)
        
        patch_data = response.get("patch")
        if not patch_data:
            print("‚ö†Ô∏è No patch generated by LLM")
            return None
        
        # Validate required fields (pseudocode is the main field now)
        required_fields = ["issue_number", "file_path", "pseudocode", "explanation", "confidence"]
        if not all(k in patch_data for k in required_fields):
            print(f"‚ö†Ô∏è Invalid patch structure - missing fields. Got keys: {list(patch_data.keys())}")
            return None
        
        # Only return patches with reasonable confidence
        if patch_data.get("confidence", 0) < 0.3:
            print(f"‚ö†Ô∏è Low confidence patch ({patch_data.get('confidence')}), skipping")
            return None
        
        return patch_data
        
    except Exception as e:
        print(f"‚ùå Error generating code patch: {e}")
        
        # Fallback: Try to extract code directly if LLM didn't return JSON
        try:
            # Sometimes LLM returns raw code instead of JSON - let's handle that
            fallback_response = await llm_client.completion(messages, temperature=0.4, max_tokens=3096)
            content = fallback_response.get("choices", [{}])[0].get("message", {}).get("content", "")
            
            if content and len(content) > 50:
                # Create a basic patch structure from raw content
                print("üîÑ Attempting fallback patch creation from raw content...")
                
                # Try to infer file path from context
                file_path = "suggested_fix.js"  # Default
                if context.get("fix_plan", {}).get("files"):
                    file_path = context["fix_plan"]["files"][0]
                
                fallback_patch = {
                    "issue_number": context["issue"]["number"],
                    "file_path": file_path,
                    "pseudocode": content[:2000],  # Limit length - treat raw output as pseudocode
                    "explanation": f"Suggested code fix for issue #{context['issue']['number']}. The AI provided code directly - please review carefully.",
                    "confidence": 0.5,  # Medium confidence for fallback
                    "approach": "fallback-parsing",
                    "notes": "This patch was extracted from a non-JSON response. Review and test thoroughly before applying.",
                    "full_code": None  # No full code in fallback mode
                }
                
                print(f"‚úÖ Fallback patch created with confidence: {fallback_patch['confidence']}")
                return fallback_patch
            
        except Exception as fallback_error:
            print(f"‚ùå Fallback also failed: {fallback_error}")
        
        return None

